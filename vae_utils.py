import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import sklearn.preprocessing as sp

from sklearn.manifold import TSNE
from sklearn.decomposition import PCA


def visualize_mnist(data_loader, num_rows=2, num_cols=5):
    """Plot random images from the MNIST dataset.

    Args:
        data_loader: Data loader for the MNIST dataset.

    Based on https://medium.com/@mrdatascience/how-to-plot-mnist-digits-using-matplotlib-65a2e0cc068
    """
    sns.set_style('white')
    num_total = num_rows * num_cols
    fig, axes = plt.subplots(num_rows, num_cols, figsize=(1.5 * num_cols, 2 * num_rows))
    for i in range(num_total):
        ax = axes[i // num_cols, i % num_cols]
        idx = np.random.randint(len(data_loader.dataset))
        x = data_loader.dataset[idx][0].view(28, 28).cpu().numpy()
        y = data_loader.dataset[idx][1]
        ax.imshow(x, cmap='gray', vmin=0.0, vmax=1.0)
        ax.set_title(f'Class: {y}')
    plt.tight_layout()
    plt.show()


def visualize_vae_samples(samples):
    """Plot random samples generated by the VAE.

    Args:
        samples: Samples drawn from the model, shape [num_samples, 28, 28]

    """
    # sns.set_style('white')
    # num_total = num_rows * num_cols
    # fig, axes = plt.subplots(num_rows, num_cols, figsize=(1.5 * num_cols, 2 * num_rows))
    # for i in range(num_total):
    #     ax = axes[i // num_cols, i % num_cols]
    #     ax.imshow(samples[i], cmap='gray', vmin=0.0, vmax=1.0)
    #     ax.set_title(f'Sample #{i}')
    # plt.tight_layout()
    # plt.show()

    # Dimensionality reduction on the embeddings using t-SNE
    tsne_s = TSNE(init='pca')
    emb_s = tsne_s.fit_transform(samples)
    plt.figure(figsize=[10, 7])
    plt.scatter(emb_s[:, 0], emb_s[:, 1], alpha=1, marker='X', s=10)


def visualize_embeddings(vae, x, y):
    sns.set_style('whitegrid')
    tsne = TSNE(init='pca')
    # pca = PCA(n_components=2)

    # Obtain embeddings using VAE
    means = vae.encoder(x)[0].cpu().detach().numpy()

    variances = vae.encoder(x)[1].cpu().detach().numpy()
    scale_var = sp.MinMaxScaler(feature_range=[0, 900])
    vars_scaled = scale_var.fit_transform(variances)
    vars_sample = np.mean(vars_scaled, axis=1)

    # Dimensionality reduction on the embeddings using t-SNE
    emb = tsne.fit_transform(means)
    # emb = pca.fit(x).transform(x)

    plt.figure(figsize=[10, 7])
    labels = y.cpu().numpy()
    for i in np.unique(labels):
        class_ind = np.where(labels == i)
        matches = class_ind[0]
        plt.scatter(emb[class_ind, 0], emb[class_ind, 1], label=f'{i}', alpha=1, marker='X', s=5)
        for n in range(0, matches.shape[0]):
            if i == 0:
                plt.scatter(emb[matches[n], 0], emb[matches[n], 1], label=f'{i}', alpha=0.2, marker='o',
                            s=vars_sample[n], c='C0')
            elif i == 1:
                plt.scatter(emb[matches[n], 0], emb[matches[n], 1], label=f'{i}', alpha=0.2, marker='o',
                            s=vars_sample[n], c='C1')
            elif i == 2:
                plt.scatter(emb[matches[n], 0], emb[matches[n], 1], label=f'{i}', alpha=0.2, marker='o',
                            s=vars_sample[n], c='C2')
            elif i == 3:
                plt.scatter(emb[matches[n], 0], emb[matches[n], 1], label=f'{i}', alpha=0.2, marker='o',
                            s=vars_sample[n], c='C3')
            else:
                pass

    plt.xlabel('t-SNE component 1')
    plt.ylabel('t-SNE component 2')
